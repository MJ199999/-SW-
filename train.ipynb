{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": ".ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1WrfhcOjDpKiRWNCv0bObT6dVbWI83Gw9",
      "authorship_tag": "ABX9TyMuxzKE0NkzhafIc0V74a1i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MJ199999/SW-Project/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncVu4X79wc-y"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/MJ199999/SW-Project/raw/master/poem_key.xlsx"
      ],
      "metadata": {
        "id": "j7n2adBtweSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel('/content/poem_key.xlsx')\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "3kKfitLzwsC_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ba00117-6a1d-4417-9b61-e078149962b5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    시인         제목                                                  시  키워드\n",
            "0  강은교  우리가 물이 되어  우리가 물이 되어 만난다면\\n가문 어느 집에선들 좋아하지 않으랴.\\n우리가 키 큰 ...  그리움\n",
            "1  김춘수   꽃을 위한 서시  나는 시방 위험한 짐승이다.\\n나의 손이 닿으면 너는 \\n미지의 까마득한 어둠이 된...  그리움\n",
            "2  김춘수          꽃  내가 그의 이름을 불러 주기 전에는\\n그는 다만\\n하나의 몸짓에 지나지 않았다. \\...  그리움\n",
            "3  김춘수         능금  그는 그리움에 산다.\\n그리움은 익어서 \\n스스로도 견디기 어려운\\n빛깔이 되고 향...  그리움\n",
            "4  김춘수       부두에서  바다에 굽힌 사나이들\\n하루의 노동을 끝낸\\n저 사나이들의 억센 팔에 안긴\\n깨지지...   노동\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = df[0:int(len(df)*0.8)]\n",
        "val_dataset = df[int(len(df)*0.8):]"
      ],
      "metadata": {
        "id": "6TBDatyawk-y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "u6Kol3xtvGDm",
        "outputId": "5f32510c-aed5-42c8-c177-4cba26eea76f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    시인         제목                                                  시  키워드\n",
              "0  강은교  우리가 물이 되어  우리가 물이 되어 만난다면\\n가문 어느 집에선들 좋아하지 않으랴.\\n우리가 키 큰 ...  그리움\n",
              "1  김춘수   꽃을 위한 서시  나는 시방 위험한 짐승이다.\\n나의 손이 닿으면 너는 \\n미지의 까마득한 어둠이 된...  그리움\n",
              "2  김춘수          꽃  내가 그의 이름을 불러 주기 전에는\\n그는 다만\\n하나의 몸짓에 지나지 않았다. \\...  그리움\n",
              "3  김춘수         능금  그는 그리움에 산다.\\n그리움은 익어서 \\n스스로도 견디기 어려운\\n빛깔이 되고 향...  그리움\n",
              "4  김춘수       부두에서  바다에 굽힌 사나이들\\n하루의 노동을 끝낸\\n저 사나이들의 억센 팔에 안긴\\n깨지지...   노동"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0c3417c7-64f0-4d93-a2f4-0f95ac46b013\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>시인</th>\n",
              "      <th>제목</th>\n",
              "      <th>시</th>\n",
              "      <th>키워드</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>강은교</td>\n",
              "      <td>우리가 물이 되어</td>\n",
              "      <td>우리가 물이 되어 만난다면\\n가문 어느 집에선들 좋아하지 않으랴.\\n우리가 키 큰 ...</td>\n",
              "      <td>그리움</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>김춘수</td>\n",
              "      <td>꽃을 위한 서시</td>\n",
              "      <td>나는 시방 위험한 짐승이다.\\n나의 손이 닿으면 너는 \\n미지의 까마득한 어둠이 된...</td>\n",
              "      <td>그리움</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>김춘수</td>\n",
              "      <td>꽃</td>\n",
              "      <td>내가 그의 이름을 불러 주기 전에는\\n그는 다만\\n하나의 몸짓에 지나지 않았다. \\...</td>\n",
              "      <td>그리움</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>김춘수</td>\n",
              "      <td>능금</td>\n",
              "      <td>그는 그리움에 산다.\\n그리움은 익어서 \\n스스로도 견디기 어려운\\n빛깔이 되고 향...</td>\n",
              "      <td>그리움</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>김춘수</td>\n",
              "      <td>부두에서</td>\n",
              "      <td>바다에 굽힌 사나이들\\n하루의 노동을 끝낸\\n저 사나이들의 억센 팔에 안긴\\n깨지지...</td>\n",
              "      <td>노동</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c3417c7-64f0-4d93-a2f4-0f95ac46b013')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0c3417c7-64f0-4d93-a2f4-0f95ac46b013 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0c3417c7-64f0-4d93-a2f4-0f95ac46b013');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, TFAutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"skt/ko-gpt-trinity-1.2B-v0.5\", bos_token='</s>', eos_token='</s>', pad_token='<pad>')\n",
        "gpt3_model = TFAutoModelForCausalLM.from_pretrained(\"skt/ko-gpt-trinity-1.2B-v0.5\", from_pt=True)"
      ],
      "metadata": {
        "id": "HL2KwfXxxcWY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a332ad1-0a69-49cb-d4ce-fad1b137295e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFGPT2LMHeadModel: ['transformer.h.1.attn.masked_bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.11.attn.masked_bias', 'transformer.h.19.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'lm_head.weight', 'transformer.h.15.attn.masked_bias', 'transformer.h.12.attn.masked_bias', 'transformer.h.17.attn.masked_bias', 'transformer.h.22.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.20.attn.masked_bias', 'transformer.h.9.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.18.attn.masked_bias', 'transformer.h.13.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.16.attn.masked_bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.23.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.21.attn.masked_bias', 'transformer.h.14.attn.masked_bias']\n",
            "- This IS expected if you are initializing TFGPT2LMHeadModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFGPT2LMHeadModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.encode(df['시'].loc[0]))\n",
        "print(tokenizer.tokenize(df['시'].loc[0]))\n",
        "print(tokenizer.decode(tokenizer.encode(df['시'].loc[0])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZbQZtNEtqcD",
        "outputId": "990ab759-f7c7-4dd3-a806-30cab4f1924b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[31171, 36238, 30726, 33577, 30298, 376, 18792, 22688, 30696, 30198, 31634, 21068, 50647, 35706, 21788, 30005, 25624, 30417, 30697, 30397, 32051, 25512, 30279, 34310, 376, 25624, 42027, 30044, 42027, 30031, 31366, 42859, 51138, 30298, 30005, 376, 29880, 31570, 33401, 24196, 30121, 22692, 20160, 25404, 376, 25960, 32086, 31241, 37797, 30092, 34682, 39172, 376, 26213, 25768, 32051, 46222, 50272, 30312, 35673, 30005, 25260, 34551, 30865, 40981, 37254, 23272, 34509, 25628, 47102, 35306, 20476, 30298, 30005, 376, 36225, 19968, 30328, 31203, 376, 23280, 21956, 31082, 21900, 30589, 23028, 24784, 565, 24471, 25820, 30164, 35031, 34264, 376, 24224, 31517, 30093, 36902, 37556, 48481, 21076, 19016, 37563, 20528, 30005, 376, 22324, 30284, 40624, 41204, 43205, 25428, 376, 25960, 30093, 30288, 32767, 40659, 29880, 30688, 30134, 21956, 31082, 34257, 29152, 24644, 24644, 31793, 24644, 24644, 30093, 32198, 30248, 42859, 30023, 30441, 376, 25492, 31296, 40455, 29979, 27588, 376, 20091, 19016, 43308, 31891, 21956, 30027, 31768]\n",
            "['▁우리가', '▁물이', '▁되어', '▁만난', '다면', '\\n', '가', '문', '▁어느', '▁집', '에선', '들', '▁좋아하지', '▁않으', '랴', '.\\n', '우', '리가', '▁키', '▁큰', '▁나무', '와', '▁함께', '▁서서', '\\n', '우', '르르', '▁우', '르르', '▁비', '오는', '▁소리로', '▁흐른', '다면', '.\\n', '\\n', '흐', '르고', '▁흘러', '서', '▁저', '물', '녘', '엔', '\\n', '저', '▁혼자', '▁깊', '어지는', '▁강', '물에', '▁누워', '\\n', '죽', '은', '▁나무', '▁뿌리를', '▁적시', '기도', '▁한다면', '.\\n', '아', '아,', '▁아직', '▁처녀', '인\\n', '부', '끄러', '운', '▁바다에', '▁닿', '는', '다면', '.\\n', '\\n', '그러', '나', '▁지금', '▁우리는', '\\n', '불', '로', '▁만나', '려', '▁한다.\\n', '벌', '써', '▁', '숯', '이', '▁된', '▁뼈', '▁하나가', '\\n', '세', '상에', '▁불', '타는', '▁것들을', '▁쓰다', '듬', '고', '▁있나', '니', '.\\n', '\\n', '만', '▁리', '▁밖에서', '▁기다리는', '▁그대', '여', '\\n', '저', '▁불', '▁지난', '▁뒤에', '▁\\n', '흐', '르는', '▁물', '로', '▁만나', '자.\\n', '푸', '시', '시', '▁푸', '시', '시', '▁불', '▁꺼', '지는', '▁소리로', '▁말', '하면서', '\\n', '올', '▁때는', '▁인적', '▁그', '친', '\\n', '넓', '고', '▁깨끗한', '▁하늘', '로', '▁오', '라.']\n",
            "우리가 물이 되어 만난다면\n",
            "가문 어느 집에선들 좋아하지 않으랴.\n",
            "우리가 키 큰 나무와 함께 서서\n",
            "우르르 우르르 비오는 소리로 흐른다면.\n",
            "\n",
            "흐르고 흘러서 저물녘엔\n",
            "저 혼자 깊어지는 강물에 누워\n",
            "죽은 나무 뿌리를 적시기도 한다면.\n",
            "아아, 아직 처녀인\n",
            "부끄러운 바다에 닿는다면.\n",
            "\n",
            "그러나 지금 우리는\n",
            "불로 만나려 한다.\n",
            "벌써 숯이 된 뼈 하나가\n",
            "세상에 불타는 것들을 쓰다듬고 있나니.\n",
            "\n",
            "만 리 밖에서 기다리는 그대여\n",
            "저 불 지난 뒤에 \n",
            "흐르는 물로 만나자.\n",
            "푸시시 푸시시 불 꺼지는 소리로 말하면서\n",
            "올 때는 인적 그친\n",
            "넓고 깨끗한 하늘로 오라.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_len = 64"
      ],
      "metadata": {
        "id": "g7Z9_jg8uxbw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "def convert_examples_to_features(examples, labels, max_seq_len, tokenizer):\n",
        "\n",
        "    input_ids, data_labels = [], []\n",
        "    \n",
        "    for example, label in tqdm(zip(examples, labels), total=len(examples)):\n",
        "\n",
        "        bos_token = [tokenizer.bos_token]\n",
        "        eos_token = [tokenizer.eos_token]\n",
        "        \n",
        "        tokens = bos_token + tokenizer.tokenize(example) + eos_token\n",
        "        input_id = tokenizer.convert_tokens_to_ids(tokens)\n",
        "        input_id = pad_sequences([input_id], maxlen=max_seq_len, value=tokenizer.pad_token_id, padding='post')[0]\n",
        "\n",
        "        output_tokens = bos_token + tokenizer.tokenize(label) + eos_token\n",
        "        output_id = tokenizer.convert_tokens_to_ids(output_tokens)\n",
        "        output_id = pad_sequences([output_id], maxlen=max_seq_len, value=tokenizer.pad_token_id, padding='post')[0]\n",
        "        \n",
        "        assert len(input_id) == max_seq_len, \"Error with input length {} vs {}\".format(len(input_id), max_seq_len)\n",
        "        input_ids.append(input_id)\n",
        "        data_labels.append(output_id)\n",
        "\n",
        "    input_ids = np.array(input_ids, dtype=int)\n",
        "    data_labels = np.array(data_labels, dtype=int)\n",
        "\n",
        "    return input_ids, data_labels"
      ],
      "metadata": {
        "id": "MAGtVbqLu0kf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X, train_y = convert_examples_to_features(train_dataset['키워드'], train_dataset['시'], max_seq_len=max_seq_len, tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "ylKyeyNBvUPW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a049caf0-b094-40c6-ec92-38be5a4c4b10"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 233/233 [00:00<00:00, 1411.88it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_X, test_y = convert_examples_to_features(val_dataset['키워드'], val_dataset['시'], max_seq_len=max_seq_len, tokenizer=tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNKTwWrF4uWq",
        "outputId": "d93cd09f-8f49-47eb-fbe5-c07fd889941e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 59/59 [00:00<00:00, 1506.24it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt3_model.transformer.wte.trainable = False"
      ],
      "metadata": {
        "id": "KFwp1uX5d_WM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "aZ38VSHo94lj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "EcoHvTjxytYj"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "gpt3_model.compile()#optimizer='adam', loss=loss)"
      ],
      "metadata": {
        "id": "QA2wRPUR9p7B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d265a76c-b5a3-4d57-a98e-e6e55302d106"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHAAQ30oLNL7",
        "outputId": "1cae308b-31bb-4874-c163-df2447a902f7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt3_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDdKuh6A2lSn",
        "outputId": "03985431-a372-48f5-f591-a436c7b48a0a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tfgpt2lm_head_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " transformer (TFGPT2MainLaye  multiple                 1162556160\n",
            " r)                                                              \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,162,556,160\n",
            "Trainable params: 1,064,252,160\n",
            "Non-trainable params: 98,304,000\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = gpt3_model.fit(train_X, train_y, epochs=3, batch_size=1, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1e1wDhbvJQe",
        "outputId": "d4911387-1bb1-459d-aab9-63f522660bf5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "209/209 [==============================] - 77s 302ms/step - loss: 8.6778 - val_loss: 7.8520\n",
            "Epoch 2/3\n",
            "209/209 [==============================] - 59s 285ms/step - loss: 7.7565 - val_loss: 7.7391\n",
            "Epoch 3/3\n",
            "209/209 [==============================] - 59s 284ms/step - loss: 7.5836 - val_loss: 7.6806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = gpt3_model.evaluate(test_X, test_y, batch_size=4)\n",
        "print(\"test loss:\", results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vk7OCF3lISY5",
        "outputId": "4fb03ffc-6bfd-455a-fcd0-8344dbeb209c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 2s 113ms/step - loss: 7.6654\n",
            "test loss: 7.665393352508545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "model_name = \"skt-ko-gpt-trinity-1.2B-v0.5\"\n",
        "save_path = os.path.join('./data_out', model_name)\n",
        "os.makedirs(save_path)\n",
        "gpt3_model.save_pretrained(save_path)"
      ],
      "metadata": {
        "id": "0U_V8OtIvjVI"
      },
      "execution_count": 24,
      "outputs": []
    }
  ]
}