{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ko_keybert.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNAHhXKPvMONWK4a00tV/Gl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MJ199999/SW-Project/blob/master/ko_keybert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://wikidocs.net/159468\n",
        "\n"
      ],
      "metadata": {
        "id": "8K3Da5hiFWh3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLhp1Ne2wCBG",
        "outputId": "86b40a2b-5aad-498d-cee0-a66a2061e5db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentence_transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 2.3 MB/s \n",
            "\u001b[?25hCollecting transformers<5.0.0,>=4.6.0\n",
            "  Downloading transformers-4.21.2-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 45.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.64.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.13.1+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.7.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (3.7)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 71.7 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub>=0.4.0\n",
            "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 71.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.1.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.8.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence_transformers) (3.0.9)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 48.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.6.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence_transformers) (3.8.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->sentence_transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->sentence_transformers) (7.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence_transformers) (7.1.2)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=4c095c603f4f14c72fb685eb799417c6a4069a23ef3907c1af0e10c31823a500\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/06/fb/d59c1e5bd1dac7f6cf61ec0036cc3a10ab8fecaa6b2c3d3ee9\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers, sentencepiece, sentence-transformers\n",
            "Successfully installed huggingface-hub-0.9.1 sentence-transformers-2.2.2 sentencepiece-0.1.97 tokenizers-0.12.1 transformers-4.21.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 5.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (453 kB)\n",
            "\u001b[K     |████████████████████████████████| 453 kB 71.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.0 konlpy-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence_transformers\n",
        "!pip install konlpy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 로드"
      ],
      "metadata": {
        "id": "EFM_HmKR3fNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import itertools\n",
        "import pandas as pd\n",
        "\n",
        "from konlpy.tag import Okt\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer"
      ],
      "metadata": {
        "id": "oEXGzG2V-4v_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1m2LYZd3Xg_",
        "outputId": "3f01face-1ad5-4a38-95a6-e337b602ac50"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('/gdrive/MyDrive/Colab Notebooks/sw-project/SW-Project/poem_key.xlsx')"
      ],
      "metadata": {
        "id": "R6Kxzblj3e3_"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "8B7wVQ1y3xiU",
        "outputId": "f25fbe2b-d0ca-4a37-a168-a672adcadccb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    시인         제목                                                  시  키워드\n",
              "0  강은교  우리가 물이 되어  우리가 물이 되어 만난다면\\n가문 어느 집에선들 좋아하지 않으랴.\\n우리가 키 큰 ...  그리움\n",
              "1  김춘수   꽃을 위한 서시  나는 시방 위험한 짐승이다.\\n나의 손이 닿으면 너는 \\n미지의 까마득한 어둠이 된...  그리움\n",
              "2  김춘수          꽃  내가 그의 이름을 불러 주기 전에는\\n그는 다만\\n하나의 몸짓에 지나지 않았다. \\...  그리움\n",
              "3  김춘수         능금  그는 그리움에 산다.\\n그리움은 익어서 \\n스스로도 견디기 어려운\\n빛깔이 되고 향...  그리움\n",
              "4  김춘수       부두에서  바다에 굽힌 사나이들\\n하루의 노동을 끝낸\\n저 사나이들의 억센 팔에 안긴\\n깨지지...   노동"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-173b1384-524a-47d9-a5ca-ddc59e47d766\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>시인</th>\n",
              "      <th>제목</th>\n",
              "      <th>시</th>\n",
              "      <th>키워드</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>강은교</td>\n",
              "      <td>우리가 물이 되어</td>\n",
              "      <td>우리가 물이 되어 만난다면\\n가문 어느 집에선들 좋아하지 않으랴.\\n우리가 키 큰 ...</td>\n",
              "      <td>그리움</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>김춘수</td>\n",
              "      <td>꽃을 위한 서시</td>\n",
              "      <td>나는 시방 위험한 짐승이다.\\n나의 손이 닿으면 너는 \\n미지의 까마득한 어둠이 된...</td>\n",
              "      <td>그리움</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>김춘수</td>\n",
              "      <td>꽃</td>\n",
              "      <td>내가 그의 이름을 불러 주기 전에는\\n그는 다만\\n하나의 몸짓에 지나지 않았다. \\...</td>\n",
              "      <td>그리움</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>김춘수</td>\n",
              "      <td>능금</td>\n",
              "      <td>그는 그리움에 산다.\\n그리움은 익어서 \\n스스로도 견디기 어려운\\n빛깔이 되고 향...</td>\n",
              "      <td>그리움</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>김춘수</td>\n",
              "      <td>부두에서</td>\n",
              "      <td>바다에 굽힌 사나이들\\n하루의 노동을 끝낸\\n저 사나이들의 억센 팔에 안긴\\n깨지지...</td>\n",
              "      <td>노동</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-173b1384-524a-47d9-a5ca-ddc59e47d766')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-173b1384-524a-47d9-a5ca-ddc59e47d766 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-173b1384-524a-47d9-a5ca-ddc59e47d766');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, len(df)):\n",
        "  poem = df['시'].iloc[i]\n",
        "  okt = Okt()\n",
        "\n",
        "  tokenized_doc = okt.pos(poem)\n",
        "  tokenized_nouns = ' '.join([word[0] for word in tokenized_doc if word[1] == 'Noun'])\n",
        "  \n",
        "  \n",
        "  n_gram_range = (1, 1)\n",
        "\n",
        "  count = CountVectorizer(ngram_range=n_gram_range).fit([tokenized_nouns])\n",
        "  candidates = count.get_feature_names_out()\n",
        "\n",
        "\n",
        "  model = SentenceTransformer('sentence-transformers/xlm-r-100langs-bert-base-nli-stsb-mean-tokens')\n",
        "  doc_embedding = model.encode([poem])\n",
        "  candidate_embeddings = model.encode(candidates)"
      ],
      "metadata": {
        "id": "gOYCsMj9BlDP"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(df1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tVN3aWvBy8a",
        "outputId": "40afa854-1c0c-49ef-9aa9-9f7cda2d1fdc"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df1.astype(\"string\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "_TrBTV0E_ObW",
        "outputId": "744915f5-124e-4eca-9205-cc83061caf42"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-268b016b51c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"string\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'astype'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = df1.to_string()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "X9UKwwoOAQXH",
        "outputId": "3400a90b-c6e7-441f-b17a-434d3fc1669a"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-63a72101939e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'to_string'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "okt = Okt()\n",
        "\n",
        "tokenized_doc = okt.pos(poem)\n",
        "tokenized_nouns = ' '.join([word[0] for word in tokenized_doc if word[1] == 'Noun'])\n",
        "\n",
        "print('품사 태깅 10개만 출력 :',tokenized_doc[:10])\n",
        "print('명사 추출 :',tokenized_nouns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guOZWToG-4_9",
        "outputId": "b31546db-af32-4856-8bb5-00cef4a12874"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "품사 태깅 10개만 출력 : [('우리', 'Noun'), ('가', 'Josa'), ('물이', 'Noun'), ('되어', 'Verb'), ('만난다면', 'Verb'), ('\\n', 'Foreign'), ('가문', 'Noun'), ('어느', 'Adverb'), ('집', 'Noun'), ('에선', 'Josa')]\n",
            "명사 추출 : 우리 물이 가문 집 우리 키 나무 서서 우르르 우르르 소리 녘 저 혼자 강물 나무 뿌리 기도 아아 처녀 바다 지금 우리 불로 벌써 숯 뼈 하나 세상 것 만 리 밖 그대 저 불 지난 뒤 물 불 소리 말 때 인적 하늘 오라\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_gram_range = (1, 1)\n",
        "\n",
        "count = CountVectorizer(ngram_range=n_gram_range).fit([tokenized_nouns])\n",
        "candidates = count.get_feature_names_out()\n",
        "\n",
        "print('trigram 개수 :',len(candidates))\n",
        "print('trigram 다섯개만 출력 :',candidates[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MX_tCTHv_Lf8",
        "outputId": "f19f7526-2c1b-4b8b-d2b3-513ef8b53827"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trigram 개수 : 24\n",
            "trigram 다섯개만 출력 : ['가문' '강물' '그대' '기도' '나무']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer('sentence-transformers/xlm-r-100langs-bert-base-nli-stsb-mean-tokens')\n",
        "doc_embedding = model.encode([df1])\n",
        "candidate_embeddings = model.encode(candidates)"
      ],
      "metadata": {
        "id": "2Cv0SrovBU4o"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_n = 5\n",
        "distances = cosine_similarity(doc_embedding, candidate_embeddings)\n",
        "keywords = [candidates[index] for index in distances.argsort()[0][-top_n:]]\n",
        "print(keywords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTshHd6yCpvP",
        "outputId": "5d15833a-c7ce-4356-f1d0-2b4e4b5c5988"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['나무', '가문', '불로', '뿌리', '강물']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def max_sum_sim(doc_embedding, candidate_embeddings, words, top_n, nr_candidates):\n",
        "    # 문서와 각 키워드들 간의 유사도\n",
        "    distances = cosine_similarity(doc_embedding, candidate_embeddings)\n",
        "\n",
        "    # 각 키워드들 간의 유사도\n",
        "    distances_candidates = cosine_similarity(candidate_embeddings, \n",
        "                                            candidate_embeddings)\n",
        "\n",
        "    # 코사인 유사도에 기반하여 키워드들 중 상위 top_n개의 단어를 pick.\n",
        "    words_idx = list(distances.argsort()[0][-nr_candidates:])\n",
        "    words_vals = [candidates[index] for index in words_idx]\n",
        "    distances_candidates = distances_candidates[np.ix_(words_idx, words_idx)]\n",
        "\n",
        "    # 각 키워드들 중에서 가장 덜 유사한 키워드들간의 조합을 계산\n",
        "    min_sim = np.inf\n",
        "    candidate = None\n",
        "    for combination in itertools.combinations(range(len(words_idx)), top_n):\n",
        "        sim = sum([distances_candidates[i][j] for i in combination for j in combination if i != j])\n",
        "        if sim < min_sim:\n",
        "            candidate = combination\n",
        "            min_sim = sim\n",
        "\n",
        "    return [words_vals[idx] for idx in candidate]"
      ],
      "metadata": {
        "id": "3IXC9zcvCrUv"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_sum_sim(doc_embedding, candidate_embeddings, candidates, top_n=5, nr_candidates=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egtWQQQhC_ID",
        "outputId": "528f4c1b-9301-4bb2-999b-8d96dcd777cd"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['처녀', '기도', '나무', '가문', '강물']"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mmr(doc_embedding, candidate_embeddings, words, top_n, diversity):\n",
        "\n",
        "    # 문서와 각 키워드들 간의 유사도가 적혀있는 리스트\n",
        "    word_doc_similarity = cosine_similarity(candidate_embeddings, doc_embedding)\n",
        "\n",
        "    # 각 키워드들 간의 유사도\n",
        "    word_similarity = cosine_similarity(candidate_embeddings)\n",
        "\n",
        "    # 문서와 가장 높은 유사도를 가진 키워드의 인덱스를 추출.\n",
        "    # 만약, 2번 문서가 가장 유사도가 높았다면\n",
        "    # keywords_idx = [2]\n",
        "    keywords_idx = [np.argmax(word_doc_similarity)]\n",
        "\n",
        "    # 가장 높은 유사도를 가진 키워드의 인덱스를 제외한 문서의 인덱스들\n",
        "    # 만약, 2번 문서가 가장 유사도가 높았다면\n",
        "    # ==> candidates_idx = [0, 1, 3, 4, 5, 6, 7, 8, 9, 10 ... 중략 ...]\n",
        "    candidates_idx = [i for i in range(len(words)) if i != keywords_idx[0]]\n",
        "\n",
        "    # 최고의 키워드는 이미 추출했으므로 top_n-1번만큼 아래를 반복.\n",
        "    # ex) top_n = 5라면, 아래의 loop는 4번 반복됨.\n",
        "    for _ in range(top_n - 1):\n",
        "        candidate_similarities = word_doc_similarity[candidates_idx, :]\n",
        "        target_similarities = np.max(word_similarity[candidates_idx][:, keywords_idx], axis=1)\n",
        "\n",
        "        # MMR을 계산\n",
        "        mmr = (1-diversity) * candidate_similarities - diversity * target_similarities.reshape(-1, 1)\n",
        "        mmr_idx = candidates_idx[np.argmax(mmr)]\n",
        "\n",
        "        # keywords & candidates를 업데이트\n",
        "        keywords_idx.append(mmr_idx)\n",
        "        candidates_idx.remove(mmr_idx)\n",
        "\n",
        "    return [words[idx] for idx in keywords_idx]"
      ],
      "metadata": {
        "id": "JIHPq3rDDBUY"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mmr(doc_embedding, candidate_embeddings, candidates, top_n=5, diversity=0.7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrSZtXILDFYt",
        "outputId": "1ee88738-fea6-4cab-fca5-f47de5f8dd68"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['강물', '처녀', '나무', '가문', '기도']"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['시'].iloc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "Xvve_cs8DHSg",
        "outputId": "979c47f5-0eba-4424-d1c8-bd6419a5a158"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'우리가 물이 되어 만난다면\\n가문 어느 집에선들 좋아하지 않으랴.\\n우리가 키 큰 나무와 함께 서서\\n우르르 우르르 비오는 소리로 흐른다면.\\n\\n흐르고 흘러서 저물녘엔\\n저 혼자 깊어지는 강물에 누워\\n죽은 나무 뿌리를 적시기도 한다면.\\n아아, 아직 처녀인\\n부끄러운 바다에 닿는다면.\\n\\n그러나 지금 우리는\\n불로 만나려 한다.\\n벌써 숯이 된 뼈 하나가\\n세상에 불타는 것들을 쓰다듬고 있나니.\\n\\n만 리 밖에서 기다리는 그대여\\n저 불 지난 뒤에 \\n흐르는 물로 만나자.\\n푸시시 푸시시 불 꺼지는 소리로 말하면서\\n올 때는 인적 그친\\n넓고 깨끗한 하늘로 오라.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L1cYjFIEDgT9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}