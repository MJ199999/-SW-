{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MJ199999/SW-Project/blob/master/code/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Install"
      ],
      "metadata": {
        "id": "alM2VoXau3bm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzpVhjBy-TyU"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncVu4X79wc-y"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Data Load & Simple Preprocess"
      ],
      "metadata": {
        "id": "SKaH-251vB70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/MJ199999/SW-Project/raw/master/poem_key.xlsx"
      ],
      "metadata": {
        "id": "Vz28DoS2P6Vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3kKfitLzwsC_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel('/gdrive/MyDrive/Colab Notebooks/sw-project/SW-Project/poem_key.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lj2i1m8BjB1k",
        "outputId": "6c19ddd5-5f0e-4884-8df1-796b83284241"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 292 entries, 0 to 291\n",
            "Data columns (total 10 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   Unnamed: 0  292 non-null    int64 \n",
            " 1   시인          292 non-null    object\n",
            " 2   제목          292 non-null    object\n",
            " 3   시           292 non-null    object\n",
            " 4   키워드 전체      290 non-null    object\n",
            " 5   키워드1        290 non-null    object\n",
            " 6   키워드2        290 non-null    object\n",
            " 7   키워드3        290 non-null    object\n",
            " 8   키워드4        290 non-null    object\n",
            " 9   키워드5        290 non-null    object\n",
            "dtypes: int64(1), object(9)\n",
            "memory usage: 22.9+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "id": "FaOWk3ejZdkH",
        "outputId": "c9e4da39-2cd2-4d3e-fc5b-985224cb3e6f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      시인         제목                                                  시  \\\n",
              "0    강은교  우리가 물이 되어  우리가 물이 되어 만난다면\\n가문 어느 집에선들 좋아하지 않으랴.\\n우리가 키 큰 ...   \n",
              "1    김춘수   꽃을 위한 서시  나는 시방 위험한 짐승이다.\\n나의 손이 닿으면 너는 \\n미지의 까마득한 어둠이 된...   \n",
              "2    김춘수          꽃  내가 그의 이름을 불러 주기 전에는\\n그는 다만\\n하나의 몸짓에 지나지 않았다. \\...   \n",
              "3    김춘수         능금  그는 그리움에 산다.\\n그리움은 익어서 \\n스스로도 견디기 어려운\\n빛깔이 되고 향...   \n",
              "4    김춘수       부두에서  바다에 굽힌 사나이들\\n하루의 노동을 끝낸\\n저 사나이들의 억센 팔에 안긴\\n깨지지...   \n",
              "..   ...        ...                                                ...   \n",
              "287  신석정        전아사  포옹할 꽃 한 송이 없는 세월을\\n얼룩진 역사의 찢긴 자락에 매달려\\n그대로 소스라...   \n",
              "288  신석정     대바람 소리  대바람 소리\\n들리더니\\n소소한 대바람 소리\\n창을 흔들더니\\n\\n소설 지낸 하늘을...   \n",
              "289  송명희          나  나, 가진 재물 없으나\\n나, 남이 가진 지식 없으나\\n나, 남에게 있는 건강 있지...   \n",
              "290  송수권    산문에 기대어  누이야\\n가을 산 그리메에 빠진 눈썹 두어 낱을\\n지금도 살아서 보는가\\n정정한 눈...   \n",
              "291   송욱       하여지향  솜덩이 같은 몸뚱아리에\\n쇳덩이처럼 무거운 집을\\n달팽이처럼 지고,\\n먼동이 아니라...   \n",
              "\n",
              "                   키워드 전체 키워드1 키워드2 키워드3 키워드4 키워드5  \n",
              "0      강물, 처녀, 나무, 가문, 기도   강물   처녀   나무   가문   기도  \n",
              "1      어둠, 신부, 울음, 짐승, 추억   어둠   신부   울음   짐승   추억  \n",
              "2      향기, 무엇, 빛깔, 모두, 눈짓   향기   무엇   빛깔   모두   눈짓  \n",
              "3     그리움, 축제, 충실, 향기, 바다  그리움   축제   충실   향기   바다  \n",
              "4      상어, 노동, 온전, 바다, 물개   상어   노동   온전   바다   물개  \n",
              "..                    ...  ...  ...  ...  ...  ...  \n",
              "287   어둠, 억만, 가을비, 포옹, 음악   어둠   억만  가을비   포옹   음악  \n",
              "288    구름, 소설, 제왕, 향기, 금은   구름   소설   제왕   향기   금은  \n",
              "289   사랑, 지식, 하나님, 재물, 음성   사랑   지식  하나님   재물   음성  \n",
              "290  물방울, 눈물, 고뇌, 가을, 물고기  물방울   눈물   고뇌   가을  물고기  \n",
              "291  달팽이, 눈초리, 두통, 자살, 거미  달팽이  눈초리   두통   자살   거미  \n",
              "\n",
              "[292 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-30f95a25-3dcf-4e72-a269-6867207ccb8c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>시인</th>\n",
              "      <th>제목</th>\n",
              "      <th>시</th>\n",
              "      <th>키워드 전체</th>\n",
              "      <th>키워드1</th>\n",
              "      <th>키워드2</th>\n",
              "      <th>키워드3</th>\n",
              "      <th>키워드4</th>\n",
              "      <th>키워드5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>강은교</td>\n",
              "      <td>우리가 물이 되어</td>\n",
              "      <td>우리가 물이 되어 만난다면\\n가문 어느 집에선들 좋아하지 않으랴.\\n우리가 키 큰 ...</td>\n",
              "      <td>강물, 처녀, 나무, 가문, 기도</td>\n",
              "      <td>강물</td>\n",
              "      <td>처녀</td>\n",
              "      <td>나무</td>\n",
              "      <td>가문</td>\n",
              "      <td>기도</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>김춘수</td>\n",
              "      <td>꽃을 위한 서시</td>\n",
              "      <td>나는 시방 위험한 짐승이다.\\n나의 손이 닿으면 너는 \\n미지의 까마득한 어둠이 된...</td>\n",
              "      <td>어둠, 신부, 울음, 짐승, 추억</td>\n",
              "      <td>어둠</td>\n",
              "      <td>신부</td>\n",
              "      <td>울음</td>\n",
              "      <td>짐승</td>\n",
              "      <td>추억</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>김춘수</td>\n",
              "      <td>꽃</td>\n",
              "      <td>내가 그의 이름을 불러 주기 전에는\\n그는 다만\\n하나의 몸짓에 지나지 않았다. \\...</td>\n",
              "      <td>향기, 무엇, 빛깔, 모두, 눈짓</td>\n",
              "      <td>향기</td>\n",
              "      <td>무엇</td>\n",
              "      <td>빛깔</td>\n",
              "      <td>모두</td>\n",
              "      <td>눈짓</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>김춘수</td>\n",
              "      <td>능금</td>\n",
              "      <td>그는 그리움에 산다.\\n그리움은 익어서 \\n스스로도 견디기 어려운\\n빛깔이 되고 향...</td>\n",
              "      <td>그리움, 축제, 충실, 향기, 바다</td>\n",
              "      <td>그리움</td>\n",
              "      <td>축제</td>\n",
              "      <td>충실</td>\n",
              "      <td>향기</td>\n",
              "      <td>바다</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>김춘수</td>\n",
              "      <td>부두에서</td>\n",
              "      <td>바다에 굽힌 사나이들\\n하루의 노동을 끝낸\\n저 사나이들의 억센 팔에 안긴\\n깨지지...</td>\n",
              "      <td>상어, 노동, 온전, 바다, 물개</td>\n",
              "      <td>상어</td>\n",
              "      <td>노동</td>\n",
              "      <td>온전</td>\n",
              "      <td>바다</td>\n",
              "      <td>물개</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>287</th>\n",
              "      <td>신석정</td>\n",
              "      <td>전아사</td>\n",
              "      <td>포옹할 꽃 한 송이 없는 세월을\\n얼룩진 역사의 찢긴 자락에 매달려\\n그대로 소스라...</td>\n",
              "      <td>어둠, 억만, 가을비, 포옹, 음악</td>\n",
              "      <td>어둠</td>\n",
              "      <td>억만</td>\n",
              "      <td>가을비</td>\n",
              "      <td>포옹</td>\n",
              "      <td>음악</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>288</th>\n",
              "      <td>신석정</td>\n",
              "      <td>대바람 소리</td>\n",
              "      <td>대바람 소리\\n들리더니\\n소소한 대바람 소리\\n창을 흔들더니\\n\\n소설 지낸 하늘을...</td>\n",
              "      <td>구름, 소설, 제왕, 향기, 금은</td>\n",
              "      <td>구름</td>\n",
              "      <td>소설</td>\n",
              "      <td>제왕</td>\n",
              "      <td>향기</td>\n",
              "      <td>금은</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>289</th>\n",
              "      <td>송명희</td>\n",
              "      <td>나</td>\n",
              "      <td>나, 가진 재물 없으나\\n나, 남이 가진 지식 없으나\\n나, 남에게 있는 건강 있지...</td>\n",
              "      <td>사랑, 지식, 하나님, 재물, 음성</td>\n",
              "      <td>사랑</td>\n",
              "      <td>지식</td>\n",
              "      <td>하나님</td>\n",
              "      <td>재물</td>\n",
              "      <td>음성</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>290</th>\n",
              "      <td>송수권</td>\n",
              "      <td>산문에 기대어</td>\n",
              "      <td>누이야\\n가을 산 그리메에 빠진 눈썹 두어 낱을\\n지금도 살아서 보는가\\n정정한 눈...</td>\n",
              "      <td>물방울, 눈물, 고뇌, 가을, 물고기</td>\n",
              "      <td>물방울</td>\n",
              "      <td>눈물</td>\n",
              "      <td>고뇌</td>\n",
              "      <td>가을</td>\n",
              "      <td>물고기</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>291</th>\n",
              "      <td>송욱</td>\n",
              "      <td>하여지향</td>\n",
              "      <td>솜덩이 같은 몸뚱아리에\\n쇳덩이처럼 무거운 집을\\n달팽이처럼 지고,\\n먼동이 아니라...</td>\n",
              "      <td>달팽이, 눈초리, 두통, 자살, 거미</td>\n",
              "      <td>달팽이</td>\n",
              "      <td>눈초리</td>\n",
              "      <td>두통</td>\n",
              "      <td>자살</td>\n",
              "      <td>거미</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>292 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30f95a25-3dcf-4e72-a269-6867207ccb8c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-30f95a25-3dcf-4e72-a269-6867207ccb8c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-30f95a25-3dcf-4e72-a269-6867207ccb8c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df.drop('Unnamed: 0', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "D6vS5gMCiywC"
      },
      "outputs": [],
      "source": [
        "df = df.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6TBDatyawk-y"
      },
      "outputs": [],
      "source": [
        "train_dataset = df\n",
        "# train_dataset = df[0:int(len(df)*0.9)]\n",
        "# val_dataset = df[int(len(df)*0.9):]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Load Tokenizer & GPT3 Model"
      ],
      "metadata": {
        "id": "iLQuMdpUvNZr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HL2KwfXxxcWY"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, TFAutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"skt/ko-gpt-trinity-1.2B-v0.5\", bos_token='</s>', eos_token='</s>', pad_token='<pad>')\n",
        "gpt3_model = TFAutoModelForCausalLM.from_pretrained(\"skt/ko-gpt-trinity-1.2B-v0.5\", from_pt=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZbQZtNEtqcD",
        "outputId": "baa6aa81-1918-4de8-999c-39f7ad5096e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[31171, 36238, 30726, 33577, 30298, 376, 18792, 22688, 30696, 30198, 31634, 21068, 50647, 35706, 21788, 30005, 25624, 30417, 30697, 30397, 32051, 25512, 30279, 34310, 376, 25624, 42027, 30044, 42027, 30031, 31366, 42859, 51138, 30298, 30005, 376, 29880, 31570, 33401, 24196, 30121, 22692, 20160, 25404, 376, 25960, 32086, 31241, 37797, 30092, 34682, 39172, 376, 26213, 25768, 32051, 46222, 50272, 30312, 35673, 30005, 25260, 34551, 30865, 40981, 37254, 23272, 34509, 25628, 47102, 35306, 20476, 30298, 30005, 376, 36225, 19968, 30328, 31203, 376, 23280, 21956, 31082, 21900, 30589, 23028, 24784, 565, 24471, 25820, 30164, 35031, 34264, 376, 24224, 31517, 30093, 36902, 37556, 48481, 21076, 19016, 37563, 20528, 30005, 376, 22324, 30284, 40624, 41204, 43205, 25428, 376, 25960, 30093, 30288, 32767, 40659, 29880, 30688, 30134, 21956, 31082, 34257, 29152, 24644, 24644, 31793, 24644, 24644, 30093, 32198, 30248, 42859, 30023, 30441, 376, 25492, 31296, 40455, 29979, 27588, 376, 20091, 19016, 43308, 31891, 21956, 30027, 31768]\n",
            "['▁우리가', '▁물이', '▁되어', '▁만난', '다면', '\\n', '가', '문', '▁어느', '▁집', '에선', '들', '▁좋아하지', '▁않으', '랴', '.\\n', '우', '리가', '▁키', '▁큰', '▁나무', '와', '▁함께', '▁서서', '\\n', '우', '르르', '▁우', '르르', '▁비', '오는', '▁소리로', '▁흐른', '다면', '.\\n', '\\n', '흐', '르고', '▁흘러', '서', '▁저', '물', '녘', '엔', '\\n', '저', '▁혼자', '▁깊', '어지는', '▁강', '물에', '▁누워', '\\n', '죽', '은', '▁나무', '▁뿌리를', '▁적시', '기도', '▁한다면', '.\\n', '아', '아,', '▁아직', '▁처녀', '인\\n', '부', '끄러', '운', '▁바다에', '▁닿', '는', '다면', '.\\n', '\\n', '그러', '나', '▁지금', '▁우리는', '\\n', '불', '로', '▁만나', '려', '▁한다.\\n', '벌', '써', '▁', '숯', '이', '▁된', '▁뼈', '▁하나가', '\\n', '세', '상에', '▁불', '타는', '▁것들을', '▁쓰다', '듬', '고', '▁있나', '니', '.\\n', '\\n', '만', '▁리', '▁밖에서', '▁기다리는', '▁그대', '여', '\\n', '저', '▁불', '▁지난', '▁뒤에', '▁\\n', '흐', '르는', '▁물', '로', '▁만나', '자.\\n', '푸', '시', '시', '▁푸', '시', '시', '▁불', '▁꺼', '지는', '▁소리로', '▁말', '하면서', '\\n', '올', '▁때는', '▁인적', '▁그', '친', '\\n', '넓', '고', '▁깨끗한', '▁하늘', '로', '▁오', '라.']\n",
            "우리가 물이 되어 만난다면\n",
            "가문 어느 집에선들 좋아하지 않으랴.\n",
            "우리가 키 큰 나무와 함께 서서\n",
            "우르르 우르르 비오는 소리로 흐른다면.\n",
            "\n",
            "흐르고 흘러서 저물녘엔\n",
            "저 혼자 깊어지는 강물에 누워\n",
            "죽은 나무 뿌리를 적시기도 한다면.\n",
            "아아, 아직 처녀인\n",
            "부끄러운 바다에 닿는다면.\n",
            "\n",
            "그러나 지금 우리는\n",
            "불로 만나려 한다.\n",
            "벌써 숯이 된 뼈 하나가\n",
            "세상에 불타는 것들을 쓰다듬고 있나니.\n",
            "\n",
            "만 리 밖에서 기다리는 그대여\n",
            "저 불 지난 뒤에 \n",
            "흐르는 물로 만나자.\n",
            "푸시시 푸시시 불 꺼지는 소리로 말하면서\n",
            "올 때는 인적 그친\n",
            "넓고 깨끗한 하늘로 오라.\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.encode(df['시'].loc[0]))\n",
        "print(tokenizer.tokenize(df['시'].loc[0]))\n",
        "print(tokenizer.decode(tokenizer.encode(df['시'].loc[0])))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Tokenize Keywords & Poems"
      ],
      "metadata": {
        "id": "tPxlXIdovUk8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "g7Z9_jg8uxbw"
      },
      "outputs": [],
      "source": [
        "max_seq_len = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MAGtVbqLu0kf"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "def convert_examples_to_features(examples, labels, max_seq_len, tokenizer):\n",
        "\n",
        "    input_ids, data_labels = [], []\n",
        "    \n",
        "    for example, label in tqdm(zip(examples, labels), total=len(examples)):\n",
        "\n",
        "        bos_token = [tokenizer.bos_token]\n",
        "        eos_token = [tokenizer.eos_token]\n",
        "        \n",
        "        tokens = bos_token + tokenizer.tokenize(example) + eos_token\n",
        "        input_id = tokenizer.convert_tokens_to_ids(tokens)\n",
        "        input_id = pad_sequences([input_id], maxlen=5, value=tokenizer.pad_token_id, padding='post')[0]\n",
        "\n",
        "        output_tokens = bos_token + tokenizer.tokenize(label) + eos_token\n",
        "        output_id = tokenizer.convert_tokens_to_ids(output_tokens)\n",
        "        output_id = pad_sequences([output_id], maxlen=max_seq_len, value=tokenizer.pad_token_id, padding='post')[0]\n",
        "        \n",
        "        assert len(input_id) == 5, \"Error with inpxut length {} vs {}\".format(len(input_id), max_seq_len)\n",
        "        input_ids.append(input_id)\n",
        "        data_labels.append(output_id)\n",
        "\n",
        "    input_ids = np.array(input_ids, dtype=int).reshape((-1,1))\n",
        "    data_labels = np.array(data_labels, dtype=int).reshape((-1,1))\n",
        "\n",
        "    return input_ids, data_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Set Train Data"
      ],
      "metadata": {
        "id": "lNkGCSdXvqAk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylKyeyNBvUPW",
        "outputId": "cb501fee-1e76-4a99-8a9c-e04b71fdceb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 290/290 [00:00<00:00, 1159.28it/s]\n"
          ]
        }
      ],
      "source": [
        "train_X_1, train_y = convert_examples_to_features(train_dataset['키워드1'], train_dataset['시'], max_seq_len=max_seq_len, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrRnKZrRbF8o",
        "outputId": "9573db68-aa8c-4690-f40c-6ac30c402ebc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 290/290 [00:00<00:00, 1282.47it/s]\n"
          ]
        }
      ],
      "source": [
        "train_X_2, train_y = convert_examples_to_features(train_dataset['키워드2'], train_dataset['시'], max_seq_len=max_seq_len, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_S1AB3BTbRE9",
        "outputId": "7de6f2d6-cf2a-4f1f-b09e-f7609e87d72b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 290/290 [00:00<00:00, 1280.84it/s]\n"
          ]
        }
      ],
      "source": [
        "train_X_3, train_y = convert_examples_to_features(train_dataset['키워드3'], train_dataset['시'], max_seq_len=max_seq_len, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPm14TRAb0zm",
        "outputId": "0bd8452f-17a8-4d1a-b14e-9617c1ce95ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 290/290 [00:00<00:00, 1261.72it/s]\n"
          ]
        }
      ],
      "source": [
        "train_X_4, train_y = convert_examples_to_features(train_dataset['키워드4'], train_dataset['시'], max_seq_len=max_seq_len, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sj70ND5b4_l",
        "outputId": "a585098f-9f15-43d2-a829-3cfae63528d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 290/290 [00:00<00:00, 1214.26it/s]\n"
          ]
        }
      ],
      "source": [
        "train_X_5, train_y = convert_examples_to_features(train_dataset['키워드5'], train_dataset['시'], max_seq_len=max_seq_len, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Freeze part of GPT3 Model"
      ],
      "metadata": {
        "id": "dwh_1fRkv4ly"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "KFwp1uX5d_WM"
      },
      "outputs": [],
      "source": [
        "gpt3_model.transformer.wte.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "zM31rsq3CQPr"
      },
      "outputs": [],
      "source": [
        "gpt3_model.transformer.h[0].trainable = False\n",
        "gpt3_model.transformer.h[1].trainable = False\n",
        "gpt3_model.transformer.h[2].trainable = False\n",
        "gpt3_model.transformer.h[3].trainable = False\n",
        "gpt3_model.transformer.h[4].trainable = False\n",
        "gpt3_model.transformer.h[5].trainable = False\n",
        "gpt3_model.transformer.h[6].trainable = False\n",
        "gpt3_model.transformer.h[7].trainable = False\n",
        "gpt3_model.transformer.h[8].trainable = False\n",
        "gpt3_model.transformer.h[9].trainable = False\n",
        "gpt3_model.transformer.h[10].trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Model Compile"
      ],
      "metadata": {
        "id": "_l1Owol4wCwy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QA2wRPUR9p7B",
        "outputId": "a1dd6de6-b6db-4999-9ad8-b9c738144364"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adagrad.py:74: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adagrad, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "optimizer = tf.keras.optimizers.Adagrad(lr=0.01)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "gpt3_model.compile(optimizer=optimizer, loss=loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDdKuh6A2lSn",
        "outputId": "e5508fbf-322d-4925-f567-19df4048b88b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"tfgpt2lm_head_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " transformer (TFGPT2MainLaye  multiple                 1162556160\n",
            " r)                                                              \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,162,556,160\n",
            "Trainable params: 577,372,800\n",
            "Non-trainable params: 585,183,360\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "gpt3_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Memory Management"
      ],
      "metadata": {
        "id": "qvoJF36ywI0I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "EcoHvTjxytYj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHAAQ30oLNL7",
        "outputId": "7c474bbe-f4d2-4838-c27d-4d5a5f09d354"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Apwtcl-XVqNS"
      },
      "source": [
        "# callbacks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss', # 모니터링 대상\n",
        "    patience=3,        # 대상 기간동안 유지\n",
        "    factor=0.5,         # 줄이는 양  \n",
        "    verbose=1,                            \n",
        "    min_learning_rate=0.00001)     # 최소 학습율"
      ],
      "metadata": {
        "id": "RQud3zUbIsSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mtb96oxGVpux"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Train Model"
      ],
      "metadata": {
        "id": "eIqHbjEDwMuS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "l1e1wDhbvJQe",
        "outputId": "ceaa6145-dfdd-4acd-decb-24b311a992dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "327/327 [==============================] - 72s 111ms/step - loss: 5.7169 - val_loss: 3.5304\n",
            "Epoch 2/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 5.0100 - val_loss: 3.6530\n",
            "Epoch 3/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.8687 - val_loss: 3.5387\n",
            "Epoch 4/100\n",
            "327/327 [==============================] - 31s 93ms/step - loss: 4.8050 - val_loss: 3.6100\n",
            "Epoch 5/100\n",
            "327/327 [==============================] - 31s 94ms/step - loss: 4.7315 - val_loss: 3.6223\n",
            "Epoch 6/100\n",
            "327/327 [==============================] - 30s 93ms/step - loss: 4.6921 - val_loss: 3.4889\n",
            "Epoch 7/100\n",
            "327/327 [==============================] - 30s 93ms/step - loss: 4.6560 - val_loss: 3.4933\n",
            "Epoch 8/100\n",
            "327/327 [==============================] - 31s 94ms/step - loss: 4.6321 - val_loss: 3.6365\n",
            "Epoch 9/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.6055 - val_loss: 3.4891\n",
            "Epoch 10/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.5618 - val_loss: 3.6536\n",
            "Epoch 11/100\n",
            "327/327 [==============================] - 31s 93ms/step - loss: 4.5825 - val_loss: 3.5618\n",
            "Epoch 12/100\n",
            "327/327 [==============================] - 30s 93ms/step - loss: 4.5609 - val_loss: 3.7817\n",
            "Epoch 13/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.5512 - val_loss: 3.5115\n",
            "Epoch 14/100\n",
            "327/327 [==============================] - 30s 93ms/step - loss: 4.5501 - val_loss: 3.5775\n",
            "Epoch 15/100\n",
            "327/327 [==============================] - 30s 93ms/step - loss: 4.5273 - val_loss: 3.5482\n",
            "Epoch 16/100\n",
            "327/327 [==============================] - 30s 93ms/step - loss: 4.5154 - val_loss: 3.6913\n",
            "Epoch 17/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.5258 - val_loss: 3.6400\n",
            "Epoch 18/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.5129 - val_loss: 3.5981\n",
            "Epoch 19/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.5081 - val_loss: 3.5471\n",
            "Epoch 20/100\n",
            "327/327 [==============================] - 30s 93ms/step - loss: 4.5072 - val_loss: 3.6058\n",
            "Epoch 21/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.5064 - val_loss: 3.5983\n",
            "Epoch 22/100\n",
            "327/327 [==============================] - 30s 93ms/step - loss: 4.4916 - val_loss: 3.6695\n",
            "Epoch 23/100\n",
            "327/327 [==============================] - 30s 93ms/step - loss: 4.4845 - val_loss: 3.6896\n",
            "Epoch 24/100\n",
            "327/327 [==============================] - 30s 93ms/step - loss: 4.4869 - val_loss: 3.5981\n",
            "Epoch 25/100\n",
            "327/327 [==============================] - 30s 93ms/step - loss: 4.4829 - val_loss: 3.6082\n",
            "Epoch 26/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.4772 - val_loss: 3.5794\n",
            "Epoch 27/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.4727 - val_loss: 3.7881\n",
            "Epoch 28/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.4689 - val_loss: 3.5904\n",
            "Epoch 29/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.4610 - val_loss: 3.9446\n",
            "Epoch 30/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.4582 - val_loss: 3.5563\n",
            "Epoch 31/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.4573 - val_loss: 3.6197\n",
            "Epoch 32/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.4610 - val_loss: 3.6313\n",
            "Epoch 33/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.4582 - val_loss: 3.6200\n",
            "Epoch 34/100\n",
            "327/327 [==============================] - 31s 94ms/step - loss: 4.4489 - val_loss: 3.5806\n",
            "Epoch 35/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.4621 - val_loss: 3.6755\n",
            "Epoch 36/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.4585 - val_loss: 3.7022\n",
            "Epoch 37/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.4448 - val_loss: 3.6683\n",
            "Epoch 38/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.4499 - val_loss: 3.7102\n",
            "Epoch 39/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.4438 - val_loss: 3.6637\n",
            "Epoch 40/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.4345 - val_loss: 3.6795\n",
            "Epoch 41/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.4323 - val_loss: 3.6784\n",
            "Epoch 42/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.4321 - val_loss: 3.6642\n",
            "Epoch 43/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.4248 - val_loss: 3.7086\n",
            "Epoch 44/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.4159 - val_loss: 3.6601\n",
            "Epoch 45/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.4037 - val_loss: 3.6954\n",
            "Epoch 46/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.4084 - val_loss: 3.6581\n",
            "Epoch 47/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.4049 - val_loss: 14.6559\n",
            "Epoch 48/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.5906 - val_loss: 3.6687\n",
            "Epoch 49/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.3548 - val_loss: 3.7453\n",
            "Epoch 50/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.3587 - val_loss: 3.7007\n",
            "Epoch 51/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.3335 - val_loss: 3.6773\n",
            "Epoch 52/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.3196 - val_loss: 3.6500\n",
            "Epoch 53/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.3084 - val_loss: 3.6168\n",
            "Epoch 54/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.3014 - val_loss: 3.6913\n",
            "Epoch 55/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.2946 - val_loss: 3.6753\n",
            "Epoch 56/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.3792 - val_loss: 3.6342\n",
            "Epoch 57/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.2899 - val_loss: 3.7675\n",
            "Epoch 58/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.2781 - val_loss: 3.7747\n",
            "Epoch 59/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.2759 - val_loss: 3.7275\n",
            "Epoch 60/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.2640 - val_loss: 3.7070\n",
            "Epoch 61/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.2640 - val_loss: 3.8113\n",
            "Epoch 62/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.2615 - val_loss: 3.7353\n",
            "Epoch 63/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.2367 - val_loss: 3.7274\n",
            "Epoch 64/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.2338 - val_loss: 3.6502\n",
            "Epoch 65/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.2302 - val_loss: 3.6790\n",
            "Epoch 66/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.2291 - val_loss: 3.6870\n",
            "Epoch 67/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.2232 - val_loss: 3.6530\n",
            "Epoch 68/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.2261 - val_loss: 3.7264\n",
            "Epoch 69/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.2225 - val_loss: 3.7297\n",
            "Epoch 70/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.2106 - val_loss: 3.7929\n",
            "Epoch 71/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.2190 - val_loss: 3.7031\n",
            "Epoch 72/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.2087 - val_loss: 3.6925\n",
            "Epoch 73/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.2005 - val_loss: 3.7132\n",
            "Epoch 74/100\n",
            "327/327 [==============================] - 30s 93ms/step - loss: 4.2067 - val_loss: 3.7100\n",
            "Epoch 75/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.1958 - val_loss: 3.7348\n",
            "Epoch 76/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.1939 - val_loss: 3.8061\n",
            "Epoch 77/100\n",
            "327/327 [==============================] - 30s 93ms/step - loss: 4.1978 - val_loss: 3.6597\n",
            "Epoch 78/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.1887 - val_loss: 3.6738\n",
            "Epoch 79/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1884 - val_loss: 3.7555\n",
            "Epoch 80/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.1813 - val_loss: 3.7634\n",
            "Epoch 81/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1937 - val_loss: 3.7589\n",
            "Epoch 82/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1820 - val_loss: 3.7456\n",
            "Epoch 83/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1854 - val_loss: 3.7495\n",
            "Epoch 84/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.1831 - val_loss: 3.8146\n",
            "Epoch 85/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1787 - val_loss: 3.7974\n",
            "Epoch 86/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1725 - val_loss: 3.7826\n",
            "Epoch 87/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.1727 - val_loss: 3.6894\n",
            "Epoch 88/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1705 - val_loss: 3.7457\n",
            "Epoch 89/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1710 - val_loss: 3.7499\n",
            "Epoch 90/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.1699 - val_loss: 3.7174\n",
            "Epoch 91/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1602 - val_loss: 3.8075\n",
            "Epoch 92/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1713 - val_loss: 3.7585\n",
            "Epoch 93/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.1640 - val_loss: 3.7224\n",
            "Epoch 94/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1623 - val_loss: 3.7184\n",
            "Epoch 95/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1525 - val_loss: 3.7119\n",
            "Epoch 96/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.1958 - val_loss: 3.7538\n",
            "Epoch 97/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1670 - val_loss: 3.7474\n",
            "Epoch 98/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1386 - val_loss: 3.8889\n",
            "Epoch 99/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.1531 - val_loss: 3.7202\n",
            "Epoch 100/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.1538 - val_loss: 3.8180\n",
            "Epoch 1/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.4005 - val_loss: 3.6368\n",
            "Epoch 2/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.3376 - val_loss: 3.6850\n",
            "Epoch 3/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.3210 - val_loss: 3.6657\n",
            "Epoch 4/100\n",
            "327/327 [==============================] - 30s 93ms/step - loss: 4.2866 - val_loss: 3.6521\n",
            "Epoch 5/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.2854 - val_loss: 3.6927\n",
            "Epoch 6/100\n",
            "327/327 [==============================] - 30s 93ms/step - loss: 4.2658 - val_loss: 3.7140\n",
            "Epoch 7/100\n",
            "327/327 [==============================] - 30s 93ms/step - loss: 4.2538 - val_loss: 3.7906\n",
            "Epoch 8/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.2510 - val_loss: 3.6752\n",
            "Epoch 9/100\n",
            "327/327 [==============================] - 30s 93ms/step - loss: 4.2399 - val_loss: 3.7303\n",
            "Epoch 10/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.2386 - val_loss: 3.7555\n",
            "Epoch 11/100\n",
            "327/327 [==============================] - 30s 93ms/step - loss: 4.2247 - val_loss: 3.7423\n",
            "Epoch 12/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.2198 - val_loss: 3.6945\n",
            "Epoch 13/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.2071 - val_loss: 3.7066\n",
            "Epoch 14/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.2040 - val_loss: 3.7440\n",
            "Epoch 15/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.2059 - val_loss: 3.8254\n",
            "Epoch 16/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.1980 - val_loss: 3.7551\n",
            "Epoch 17/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1891 - val_loss: 3.8293\n",
            "Epoch 18/100\n",
            "327/327 [==============================] - 31s 93ms/step - loss: 4.1890 - val_loss: 3.7393\n",
            "Epoch 19/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.1855 - val_loss: 3.7099\n",
            "Epoch 20/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.1792 - val_loss: 3.7226\n",
            "Epoch 21/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.1845 - val_loss: 3.7789\n",
            "Epoch 22/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.1759 - val_loss: 3.7981\n",
            "Epoch 23/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.1743 - val_loss: 3.7802\n",
            "Epoch 24/100\n",
            "327/327 [==============================] - 30s 93ms/step - loss: 4.1708 - val_loss: 3.7385\n",
            "Epoch 25/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1610 - val_loss: 3.7507\n",
            "Epoch 26/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1601 - val_loss: 3.7181\n",
            "Epoch 27/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1656 - val_loss: 3.7939\n",
            "Epoch 28/100\n",
            "327/327 [==============================] - 30s 93ms/step - loss: 4.1687 - val_loss: 3.7243\n",
            "Epoch 29/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1634 - val_loss: 3.7822\n",
            "Epoch 30/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1682 - val_loss: 3.7360\n",
            "Epoch 31/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.1557 - val_loss: 3.7764\n",
            "Epoch 32/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1504 - val_loss: 3.7204\n",
            "Epoch 33/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1594 - val_loss: 3.8173\n",
            "Epoch 34/100\n",
            "327/327 [==============================] - 30s 93ms/step - loss: 4.1609 - val_loss: 3.7927\n",
            "Epoch 35/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.1588 - val_loss: 3.7606\n",
            "Epoch 36/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1360 - val_loss: 3.7016\n",
            "Epoch 37/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.1577 - val_loss: 3.7447\n",
            "Epoch 38/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1461 - val_loss: 3.7354\n",
            "Epoch 39/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1468 - val_loss: 3.7615\n",
            "Epoch 40/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1481 - val_loss: 3.7744\n",
            "Epoch 41/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1414 - val_loss: 3.7199\n",
            "Epoch 42/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1410 - val_loss: 3.7967\n",
            "Epoch 43/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1375 - val_loss: 3.7561\n",
            "Epoch 44/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.1371 - val_loss: 3.7836\n",
            "Epoch 45/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1391 - val_loss: 3.7429\n",
            "Epoch 46/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1386 - val_loss: 3.8135\n",
            "Epoch 47/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.1350 - val_loss: 3.7793\n",
            "Epoch 48/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1292 - val_loss: 3.7330\n",
            "Epoch 49/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1323 - val_loss: 3.8346\n",
            "Epoch 50/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1371 - val_loss: 3.8609\n",
            "Epoch 51/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1345 - val_loss: 3.7766\n",
            "Epoch 52/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1253 - val_loss: 3.8542\n",
            "Epoch 53/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1336 - val_loss: 3.7041\n",
            "Epoch 54/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.1279 - val_loss: 3.8337\n",
            "Epoch 55/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1367 - val_loss: 3.7546\n",
            "Epoch 56/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1280 - val_loss: 3.7940\n",
            "Epoch 57/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.1330 - val_loss: 3.7973\n",
            "Epoch 58/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.1275 - val_loss: 3.7141\n",
            "Epoch 59/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.1196 - val_loss: 3.7463\n",
            "Epoch 60/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.1318 - val_loss: 3.7893\n",
            "Epoch 61/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.1147 - val_loss: 3.7639\n",
            "Epoch 62/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1220 - val_loss: 3.7304\n",
            "Epoch 63/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1238 - val_loss: 3.7981\n",
            "Epoch 64/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.1189 - val_loss: 3.7478\n",
            "Epoch 65/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1242 - val_loss: 3.7378\n",
            "Epoch 66/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1112 - val_loss: 3.7769\n",
            "Epoch 67/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.1175 - val_loss: 3.7517\n",
            "Epoch 68/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1159 - val_loss: 3.8364\n",
            "Epoch 69/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1159 - val_loss: 3.8175\n",
            "Epoch 70/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.1137 - val_loss: 3.8201\n",
            "Epoch 71/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1112 - val_loss: 3.7052\n",
            "Epoch 72/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1065 - val_loss: 3.7725\n",
            "Epoch 73/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1119 - val_loss: 3.8035\n",
            "Epoch 74/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.1035 - val_loss: 3.7495\n",
            "Epoch 75/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1034 - val_loss: 3.8561\n",
            "Epoch 76/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.0946 - val_loss: 3.8329\n",
            "Epoch 77/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.0917 - val_loss: 3.7994\n",
            "Epoch 78/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.0844 - val_loss: 3.8547\n",
            "Epoch 79/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.0823 - val_loss: 3.7656\n",
            "Epoch 80/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.0786 - val_loss: 3.7927\n",
            "Epoch 81/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.0917 - val_loss: 3.7649\n",
            "Epoch 82/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.0675 - val_loss: 3.8426\n",
            "Epoch 83/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.0750 - val_loss: 3.8218\n",
            "Epoch 84/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.0928 - val_loss: 3.8334\n",
            "Epoch 85/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.0629 - val_loss: 3.7890\n",
            "Epoch 86/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.0580 - val_loss: 3.8431\n",
            "Epoch 87/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.0483 - val_loss: 3.8152\n",
            "Epoch 88/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.0279 - val_loss: 3.8629\n",
            "Epoch 89/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.0324 - val_loss: 3.9404\n",
            "Epoch 90/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.0180 - val_loss: 3.8333\n",
            "Epoch 91/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.0094 - val_loss: 3.8020\n",
            "Epoch 92/100\n",
            "327/327 [==============================] - 30s 90ms/step - loss: 4.0069 - val_loss: 3.8527\n",
            "Epoch 93/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.9971 - val_loss: 3.8744\n",
            "Epoch 94/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.0032 - val_loss: 3.8184\n",
            "Epoch 95/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.9885 - val_loss: 3.9465\n",
            "Epoch 96/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.9897 - val_loss: 3.9756\n",
            "Epoch 97/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.9770 - val_loss: 3.8774\n",
            "Epoch 98/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.9804 - val_loss: 3.8721\n",
            "Epoch 99/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.9751 - val_loss: 3.8688\n",
            "Epoch 100/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.9719 - val_loss: 3.8092\n",
            "Epoch 1/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.2509 - val_loss: 3.7847\n",
            "Epoch 2/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.2058 - val_loss: 3.7738\n",
            "Epoch 3/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.1686 - val_loss: 3.8021\n",
            "Epoch 4/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.1439 - val_loss: 3.8456\n",
            "Epoch 5/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.1184 - val_loss: 3.8252\n",
            "Epoch 6/100\n",
            "327/327 [==============================] - 30s 90ms/step - loss: 4.1094 - val_loss: 3.8128\n",
            "Epoch 7/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.0991 - val_loss: 3.8176\n",
            "Epoch 8/100\n",
            "327/327 [==============================] - 30s 90ms/step - loss: 4.0760 - val_loss: 3.8115\n",
            "Epoch 9/100\n",
            "327/327 [==============================] - 30s 90ms/step - loss: 4.0706 - val_loss: 3.7812\n",
            "Epoch 10/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.0584 - val_loss: 3.7933\n",
            "Epoch 11/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.0506 - val_loss: 3.7995\n",
            "Epoch 12/100\n",
            "327/327 [==============================] - 30s 90ms/step - loss: 4.0497 - val_loss: 3.8683\n",
            "Epoch 13/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.0339 - val_loss: 3.8236\n",
            "Epoch 14/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.0274 - val_loss: 3.9132\n",
            "Epoch 15/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.0152 - val_loss: 3.8592\n",
            "Epoch 16/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.0107 - val_loss: 3.8654\n",
            "Epoch 17/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.0147 - val_loss: 3.8772\n",
            "Epoch 18/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.9926 - val_loss: 3.9204\n",
            "Epoch 19/100\n",
            "327/327 [==============================] - 30s 90ms/step - loss: 3.9933 - val_loss: 3.8398\n",
            "Epoch 20/100\n",
            "327/327 [==============================] - 30s 90ms/step - loss: 3.9990 - val_loss: 3.9314\n",
            "Epoch 21/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.9871 - val_loss: 3.8742\n",
            "Epoch 22/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.9838 - val_loss: 3.8578\n",
            "Epoch 23/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.9848 - val_loss: 3.8929\n",
            "Epoch 24/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.9789 - val_loss: 3.8591\n",
            "Epoch 25/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.9688 - val_loss: 3.9152\n",
            "Epoch 26/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.9675 - val_loss: 3.9438\n",
            "Epoch 27/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.9719 - val_loss: 3.9227\n",
            "Epoch 28/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.9690 - val_loss: 3.9321\n",
            "Epoch 29/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 3.9603 - val_loss: 3.9553\n",
            "Epoch 30/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 3.9645 - val_loss: 3.9072\n",
            "Epoch 31/100\n",
            "327/327 [==============================] - 31s 94ms/step - loss: 3.9592 - val_loss: 3.9107\n",
            "Epoch 32/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 3.9466 - val_loss: 3.8384\n",
            "Epoch 33/100\n",
            "327/327 [==============================] - 31s 93ms/step - loss: 3.9413 - val_loss: 3.9288\n",
            "Epoch 34/100\n",
            "327/327 [==============================] - 31s 93ms/step - loss: 3.9455 - val_loss: 3.8780\n",
            "Epoch 35/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.9286 - val_loss: 3.8985\n",
            "Epoch 36/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 3.9337 - val_loss: 3.8981\n",
            "Epoch 37/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.9397 - val_loss: 3.8626\n",
            "Epoch 38/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.9346 - val_loss: 3.9059\n",
            "Epoch 39/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.9266 - val_loss: 3.8802\n",
            "Epoch 40/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.9256 - val_loss: 3.9523\n",
            "Epoch 41/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.9196 - val_loss: 3.9093\n",
            "Epoch 42/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.9241 - val_loss: 3.9745\n",
            "Epoch 43/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.9134 - val_loss: 3.8931\n",
            "Epoch 44/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.9045 - val_loss: 3.8525\n",
            "Epoch 45/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.9138 - val_loss: 3.9362\n",
            "Epoch 46/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.9117 - val_loss: 3.8676\n",
            "Epoch 47/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.9103 - val_loss: 3.9428\n",
            "Epoch 48/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 3.8939 - val_loss: 3.9413\n",
            "Epoch 49/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.9027 - val_loss: 3.8737\n",
            "Epoch 50/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.9002 - val_loss: 3.9166\n",
            "Epoch 51/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.9000 - val_loss: 3.9954\n",
            "Epoch 52/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.9020 - val_loss: 3.9575\n",
            "Epoch 53/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.8813 - val_loss: 3.9886\n",
            "Epoch 54/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.8836 - val_loss: 3.9168\n",
            "Epoch 55/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.8748 - val_loss: 3.9642\n",
            "Epoch 56/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.8738 - val_loss: 3.9099\n",
            "Epoch 57/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.8812 - val_loss: 3.9119\n",
            "Epoch 58/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 3.8668 - val_loss: 3.9538\n",
            "Epoch 59/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.8644 - val_loss: 3.9120\n",
            "Epoch 60/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.8613 - val_loss: 3.8845\n",
            "Epoch 61/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.8578 - val_loss: 3.9061\n",
            "Epoch 62/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.8669 - val_loss: 3.9742\n",
            "Epoch 63/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.8429 - val_loss: 3.9022\n",
            "Epoch 64/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.8358 - val_loss: 3.9506\n",
            "Epoch 65/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.8320 - val_loss: 3.9014\n",
            "Epoch 66/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.8385 - val_loss: 3.9500\n",
            "Epoch 67/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.8200 - val_loss: 3.9717\n",
            "Epoch 68/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.8252 - val_loss: 3.9821\n",
            "Epoch 69/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 3.8194 - val_loss: 3.9681\n",
            "Epoch 70/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.8017 - val_loss: 4.0172\n",
            "Epoch 71/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.7952 - val_loss: 4.0173\n",
            "Epoch 72/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.8058 - val_loss: 4.0145\n",
            "Epoch 73/100\n",
            "327/327 [==============================] - 30s 90ms/step - loss: 3.7958 - val_loss: 4.1217\n",
            "Epoch 74/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.7822 - val_loss: 3.9566\n",
            "Epoch 75/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.7761 - val_loss: 4.0231\n",
            "Epoch 76/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.7845 - val_loss: 4.0178\n",
            "Epoch 77/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.7575 - val_loss: 4.0752\n",
            "Epoch 78/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.7613 - val_loss: 3.9961\n",
            "Epoch 79/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 3.7651 - val_loss: 3.9486\n",
            "Epoch 80/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.7562 - val_loss: 4.0551\n",
            "Epoch 81/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.7316 - val_loss: 4.0915\n",
            "Epoch 82/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.7382 - val_loss: 4.0066\n",
            "Epoch 83/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.7397 - val_loss: 4.0241\n",
            "Epoch 84/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.7169 - val_loss: 4.0080\n",
            "Epoch 85/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.7153 - val_loss: 4.1183\n",
            "Epoch 86/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.7010 - val_loss: 4.0423\n",
            "Epoch 87/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.7086 - val_loss: 4.2043\n",
            "Epoch 88/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.6915 - val_loss: 4.0497\n",
            "Epoch 89/100\n",
            "327/327 [==============================] - 30s 90ms/step - loss: 3.6822 - val_loss: 4.1360\n",
            "Epoch 90/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.6717 - val_loss: 4.2108\n",
            "Epoch 91/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.6897 - val_loss: 4.0401\n",
            "Epoch 92/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.6791 - val_loss: 4.0088\n",
            "Epoch 93/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.6725 - val_loss: 4.1473\n",
            "Epoch 94/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.6546 - val_loss: 4.2146\n",
            "Epoch 95/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.6476 - val_loss: 4.2216\n",
            "Epoch 96/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.6507 - val_loss: 4.1222\n",
            "Epoch 97/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 3.6338 - val_loss: 4.1919\n",
            "Epoch 98/100\n",
            "327/327 [==============================] - 30s 90ms/step - loss: 3.6408 - val_loss: 4.0676\n",
            "Epoch 99/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.6098 - val_loss: 4.1865\n",
            "Epoch 100/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.6209 - val_loss: 4.1820\n",
            "Epoch 1/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.2933 - val_loss: 3.8453\n",
            "Epoch 2/100\n",
            "327/327 [==============================] - 30s 93ms/step - loss: 4.1582 - val_loss: 3.7681\n",
            "Epoch 3/100\n",
            "327/327 [==============================] - 30s 93ms/step - loss: 4.1091 - val_loss: 3.7972\n",
            "Epoch 4/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.0804 - val_loss: 3.8426\n",
            "Epoch 5/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 4.0445 - val_loss: 3.7977\n",
            "Epoch 6/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 4.0202 - val_loss: 3.8359\n",
            "Epoch 7/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 3.9994 - val_loss: 3.8475\n",
            "Epoch 8/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.9671 - val_loss: 3.8467\n",
            "Epoch 9/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.9339 - val_loss: 3.8930\n",
            "Epoch 10/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.9480 - val_loss: 3.8564\n",
            "Epoch 11/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 3.9095 - val_loss: 3.8375\n",
            "Epoch 12/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.8828 - val_loss: 3.9540\n",
            "Epoch 13/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.8615 - val_loss: 3.8453\n",
            "Epoch 14/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 3.8507 - val_loss: 3.9528\n",
            "Epoch 15/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.8355 - val_loss: 3.8859\n",
            "Epoch 16/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.8133 - val_loss: 3.9845\n",
            "Epoch 17/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.7817 - val_loss: 3.8390\n",
            "Epoch 18/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 3.7792 - val_loss: 3.9477\n",
            "Epoch 19/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.7517 - val_loss: 3.9096\n",
            "Epoch 20/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.7407 - val_loss: 3.9036\n",
            "Epoch 21/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.7367 - val_loss: 3.8972\n",
            "Epoch 22/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.7043 - val_loss: 3.9706\n",
            "Epoch 23/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.6974 - val_loss: 3.9250\n",
            "Epoch 24/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.6815 - val_loss: 3.9428\n",
            "Epoch 25/100\n",
            "327/327 [==============================] - 31s 94ms/step - loss: 3.6619 - val_loss: 4.0088\n",
            "Epoch 26/100\n",
            "327/327 [==============================] - 31s 95ms/step - loss: 3.6394 - val_loss: 3.9160\n",
            "Epoch 27/100\n",
            "327/327 [==============================] - 31s 94ms/step - loss: 3.6241 - val_loss: 3.9014\n",
            "Epoch 28/100\n",
            "327/327 [==============================] - 31s 96ms/step - loss: 3.5924 - val_loss: 4.0939\n",
            "Epoch 29/100\n",
            "327/327 [==============================] - 31s 94ms/step - loss: 3.5924 - val_loss: 4.0380\n",
            "Epoch 30/100\n",
            "327/327 [==============================] - 30s 92ms/step - loss: 3.5609 - val_loss: 4.0929\n",
            "Epoch 31/100\n",
            "327/327 [==============================] - 30s 91ms/step - loss: 3.5518 - val_loss: 4.1618\n",
            "Epoch 32/100\n",
            "327/327 [==============================] - 30s 93ms/step - loss: 3.5375 - val_loss: 4.0518\n",
            "Epoch 33/100\n",
            "327/327 [==============================] - 31s 93ms/step - loss: 3.5161 - val_loss: 4.1455\n",
            "Epoch 34/100\n",
            "327/327 [==============================] - 31s 94ms/step - loss: 3.5121 - val_loss: 4.1732\n",
            "Epoch 35/100\n",
            "327/327 [==============================] - 31s 95ms/step - loss: 3.4970 - val_loss: 4.0660\n",
            "Epoch 36/100\n",
            "327/327 [==============================] - 31s 96ms/step - loss: 3.4846 - val_loss: 4.1947\n",
            "Epoch 37/100\n",
            "327/327 [==============================] - 31s 95ms/step - loss: 3.4628 - val_loss: 4.1822\n",
            "Epoch 38/100\n",
            "327/327 [==============================] - 31s 94ms/step - loss: 3.4518 - val_loss: 4.1721\n",
            "Epoch 39/100\n",
            "327/327 [==============================] - 31s 95ms/step - loss: 3.4271 - val_loss: 4.0498\n",
            "Epoch 40/100\n",
            "327/327 [==============================] - 31s 94ms/step - loss: 3.4338 - val_loss: 4.4604\n",
            "Epoch 41/100\n",
            "327/327 [==============================] - 31s 94ms/step - loss: 3.3863 - val_loss: 4.3979\n",
            "Epoch 42/100\n",
            "327/327 [==============================] - 31s 94ms/step - loss: 3.3816 - val_loss: 4.5292\n",
            "Epoch 43/100\n",
            "327/327 [==============================] - 31s 94ms/step - loss: 3.3875 - val_loss: 4.3243\n",
            "Epoch 44/100\n",
            "327/327 [==============================] - 31s 94ms/step - loss: 3.3591 - val_loss: 4.3980\n",
            "Epoch 45/100\n",
            "327/327 [==============================] - 31s 93ms/step - loss: 3.3431 - val_loss: 4.5103\n",
            "Epoch 46/100\n",
            "327/327 [==============================] - 31s 95ms/step - loss: 3.3316 - val_loss: 4.1896\n",
            "Epoch 47/100\n",
            "327/327 [==============================] - 31s 95ms/step - loss: 3.3189 - val_loss: 4.4818\n",
            "Epoch 48/100\n",
            "327/327 [==============================] - 30s 93ms/step - loss: 3.2972 - val_loss: 4.4391\n",
            "Epoch 49/100\n",
            "327/327 [==============================] - 30s 93ms/step - loss: 3.2885 - val_loss: 4.3361\n",
            "Epoch 50/100\n",
            "327/327 [==============================] - 31s 96ms/step - loss: 3.2645 - val_loss: 4.5439\n",
            "Epoch 51/100\n",
            "327/327 [==============================] - 31s 94ms/step - loss: 3.2664 - val_loss: 4.4097\n",
            "Epoch 52/100\n",
            "327/327 [==============================] - 31s 96ms/step - loss: 3.2543 - val_loss: 4.4858\n",
            "Epoch 53/100\n",
            "327/327 [==============================] - 31s 96ms/step - loss: 3.2120 - val_loss: 4.5541\n",
            "Epoch 54/100\n",
            "327/327 [==============================] - 31s 96ms/step - loss: 3.2424 - val_loss: 4.5732\n",
            "Epoch 55/100\n",
            "327/327 [==============================] - 31s 96ms/step - loss: 3.2262 - val_loss: 4.5844\n",
            "Epoch 56/100\n",
            "327/327 [==============================] - 31s 96ms/step - loss: 3.1955 - val_loss: 4.6682\n",
            "Epoch 57/100\n",
            "327/327 [==============================] - 31s 96ms/step - loss: 3.1563 - val_loss: 4.7267\n",
            "Epoch 58/100\n",
            "327/327 [==============================] - 31s 96ms/step - loss: 3.1883 - val_loss: 4.6144\n",
            "Epoch 59/100\n",
            "327/327 [==============================] - 31s 96ms/step - loss: 3.1198 - val_loss: 4.7874\n",
            "Epoch 60/100\n",
            "327/327 [==============================] - 32s 97ms/step - loss: 3.1084 - val_loss: 4.8296\n",
            "Epoch 61/100\n",
            "327/327 [==============================] - 31s 96ms/step - loss: 3.1232 - val_loss: 4.4992\n",
            "Epoch 62/100\n",
            "327/327 [==============================] - 31s 96ms/step - loss: 3.0963 - val_loss: 4.7026\n",
            "Epoch 63/100\n",
            "327/327 [==============================] - 32s 96ms/step - loss: 3.0883 - val_loss: 4.7781\n",
            "Epoch 64/100\n",
            " 16/327 [>.............................] - ETA: 30s - loss: 3.2019"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-78d0e28aeda7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgpt3_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgpt3_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgpt3_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mgpt3_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "gpt3_model.fit(train_X_1, train_y, epochs=100, batch_size=4, validation_split=0.1)\n",
        "gpt3_model.fit(train_X_2, train_y, epochs=100, batch_size=4, validation_split=0.1)\n",
        "gpt3_model.fit(train_X_3, train_y, epochs=100, batch_size=4, validation_split=0.1)\n",
        "gpt3_model.fit(train_X_4, train_y, epochs=100, batch_size=4, validation_split=0.1)\n",
        "gpt3_model.fit(train_X_5, train_y, epochs=100, batch_size=4, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Tokenize Test Input"
      ],
      "metadata": {
        "id": "IMrk-qSTwQy4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "LQVMLcAxpyf8"
      },
      "outputs": [],
      "source": [
        "max_key_len=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_fyo2HO0qcad"
      },
      "outputs": [],
      "source": [
        "keyword = \"가을\"\n",
        "\n",
        "bos_token = [tokenizer.bos_token]\n",
        "eos_token = [tokenizer.eos_token]\n",
        "\n",
        "tokens = bos_token + tokenizer.tokenize(keyword) + eos_token\n",
        "input_id = tokenizer.convert_tokens_to_ids(tokens)\n",
        "input_id = pad_sequences([input_id], maxlen=max_key_len, value=tokenizer.pad_token_id, padding='post')[0]\n",
        "\n",
        "input_id = np.array(input_id, dtype=int).reshape((-1,1))\n",
        "\n",
        "input_ids1 = tokenizer(keyword, return_tensors='pt').input_ids\n",
        "#input_ids1.unsqueeze(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. Generate Poem"
      ],
      "metadata": {
        "id": "YkYkFmjqwdaI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "NH9JFkjgpvm7"
      },
      "outputs": [],
      "source": [
        "gen_id = gpt3_model.generate(input_id, do_sample=False, min_length = 15, max_length=100, repetition_penalty=8.0, top_k=50, top_p=0.92,temperature=1.0, no_repeat_ngram_size=2)\n",
        "gen_text = tokenizer.batch_decode(gen_id, skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCoD_5Ty-KpA",
        "outputId": "e9d728cb-dfbc-4eb7-8de1-9bcd2279ff9f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n이 불불부 싶다.지지 나는놋 싶다.\\n 끝 깨끗한상에은 없는음은상의상은개 이름도 나무에선이다.\\n우 날 않는만 새 스미상에서비오는재의재는 없이 이름을높 빛움은들\\n 그의존 그 너 그는친날한',\n",
              " '가을음은 않는 날 여움은 스미 불 없는은상에개 이름도 나무에선 넓은 새들\\n우 그상은상의이재의재는 빛 이름은 온존\\n 너 그의 이름을이다.\\n높 그는이\\n 바다 않았다.\\n날한그러 없이 높이 우상에서만오는 있다.\\n',\n",
              " '\\n이 불불부 싶다.지지 나는놋 싶다.\\n 끝 깨끗한상에은 없는음은상의상은개 이름도 나무에선이다.\\n우 날 않는만 새 스미상에서비오는재의재는 없이 이름을높 빛움은들\\n 그의존 그 너 그는친날한',\n",
              " '\\n \\n 불러의가은 눈.\\n 부부 모두 벗 없는 싶다. 된다.\\n 이 된비나는상에개 이름도 나무이인\\n이다.\\n에선 날들\\n오는 새우 이름을 빛높저 않는 온문\\n 그 그의움은 스미 그는 이름은상의상은',\n",
              " '\\n \\n 불러의가은 눈.\\n 부부 모두 벗 없는 싶다. 된다.\\n 이 된비나는상에개 이름도 나무이인\\n이다.\\n에선 날들\\n오는 새우 이름을 빛높저 않는 온문\\n 그 그의움은 스미 그는 이름은상의상은']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "gen_text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12. Model Save"
      ],
      "metadata": {
        "id": "YCGexs8Dwn5A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0U_V8OtIvjVI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "model_name = \"skt-ko-gpt-trinity-1.2B-v0.5-4\"\n",
        "save_path = os.path.join('/gdrive/MyDrive/Colab Notebooks/sw-project/SW-Project/', model_name)\n",
        "os.makedirs(save_path)\n",
        "gpt3_model.save_pretrained(save_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1WrfhcOjDpKiRWNCv0bObT6dVbWI83Gw9",
      "authorship_tag": "ABX9TyN7Q7zvY7ULTDqfaXhLT1+n",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}